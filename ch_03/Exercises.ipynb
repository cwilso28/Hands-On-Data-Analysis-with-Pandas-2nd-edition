{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ef4d7c",
   "metadata": {},
   "source": [
    "# Ch. 3 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d6028",
   "metadata": {},
   "source": [
    "1. We want to look at data for the Facebook, Apple, Amazon, Netflix, and Google (FAANG) stocks, but we were given each as a separate CSV file (obtained using the `stock_analysis` package we will build in *Chapter 7, Financial Analysis â€“ Bitcoin and the Stock Market*). Combine them into a single file and store the dataframe of the FAANG data as faang for the rest of the exercises:\n",
    "    1. Read in the `aapl.csv`, `amzn.csv`, `fb.csv`, `goog.csv`, and `nflx.csv` files.\n",
    "    2. Add a column to each dataframe, called `ticker`, indicating the ticker symbol it is for (Apple's is AAPL, for example); this is how you look up a stock. In this case, the filenames happen to be the ticker symbols.\n",
    "    3. Append them together into a single dataframe.\n",
    "    4. Save the result in a CSV file called `faang.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bf7fc",
   "metadata": {},
   "source": [
    "2. With `faang`, use type conversion to cast the values of the `date` column into datetimes and the `volume` column into integers. Then, sort by `date` and `ticker`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b10e83",
   "metadata": {},
   "source": [
    "3. Find the seven rows in `faang` with the lowest value for volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc0720",
   "metadata": {},
   "source": [
    "4. Right now, the data is somewhere between long and wide format. Use `melt()` to make it completely long format. Hint: `date` and `ticker` are our ID variables (they uniquely identify each row). We need to melt the rest so that we don't have separate columns for `open`, `high`, `low`, `close`, and `volume`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b436a1e",
   "metadata": {},
   "source": [
    "5. Suppose we found out that on July 26, 2018 there was a glitch in how the data was recorded. How should we handle this? Note that there is no coding required for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c4dea",
   "metadata": {},
   "source": [
    "6. The **European Centre for Disease Prevention and Control (ECDC)** provides an open dataset on COVID-19 cases called *daily number of new reported cases of COVID-19 by country worldwide* (https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographicdistribution-covid-19-cases-worldwide). This dataset is updated daily, but we will use a snapshot that contains data from January 1, 2020 through September 18, 2020. Clean and pivot the data so that it is in wide format:\n",
    "   1. Read in the `covid19_cases.csv` file.\n",
    "   2. Create a `date` column using the data in the `dateRep` column and the `pd.to_datetime()` function.\n",
    "   3. Set the `date` column as the index and sort the index.\n",
    "   4. Replace all occurrences of `United_States_of_America` and `United_Kingdom` with `USA` and `UK`, respectively. Hint: the `replace()` method can be run on the dataframe as a whole.\n",
    "   5. Using the `countriesAndTerritories` column, filter the cleaned COVID-19 cases data down to Argentina, Brazil, China, Colombia, India, Italy, Mexico, Peru, Russia, Spain, Turkey, the UK, and the USA.\n",
    "   6. Pivot the data so that the index contains the dates, the columns contain the country names, and the values are the case counts (the `cases` column). Be sure to fill in `NaN` values with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a89835",
   "metadata": {},
   "source": [
    "7. In order to determine the case totals per country efficiently, we need the aggregation skills we will learn about in *Chapter 4, Aggregating Pandas DataFrames*, so the ECDC data in the `covid19_cases.csv` file has been aggregated for us and saved in the `covid19_total_cases.csv` file. It contains the total number of cases per country. Use this data to find the 20 countries with the largest COVID-19 case totals. Hints: when reading in the CSV file, pass in `index_col='cases'`, and note that it will be helpful to transpose the data before isolating the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01eb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".book_env",
   "language": "python",
   "name": ".book_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
