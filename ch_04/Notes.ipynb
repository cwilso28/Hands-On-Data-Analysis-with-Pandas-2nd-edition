{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a3acb",
   "metadata": {},
   "source": [
    "# Chapter 4 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32769663",
   "metadata": {},
   "source": [
    "### Database-stype operations in Pandas\n",
    "SQL like operations can be performed in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52c198",
   "metadata": {},
   "source": [
    "#### Querying\n",
    "- The `query()` method can be used to write filters instead of using a Boolean mask\n",
    "  - The syntax is similar to the `WHERE` clause\n",
    "  - This method is especially useful with long dataframe names, but it's similar to Boolean masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569b4a2",
   "metadata": {},
   "source": [
    "#### Merging\n",
    "- There are four types of joins: full (outer), left, right, and inner\n",
    "- The previously discussed methods, `pd.concat()` and `append()` methods mimic the SQL `UNION ALL` and `UNION` statements\n",
    "- Inner joins:\n",
    "  - Returns the columns from both dataframes where they match on the specific key column\n",
    "  - This can be performed with the `merge()` method\n",
    "    - The dataframe that the `merge()` method is called on is the left dataframe and the right is the dataframe passed to the method\n",
    "    - The columns to match on can be specified if the two dataframe columns have different names\n",
    "- Left and right joins:\n",
    "  - Can also be performed with the `merge()` method using the `how` input\n",
    "  - Right joins are the inverse of the left join call\n",
    "- Outer joins:\n",
    "  - Can also be performed with the `merge()` method and `how` input\n",
    "- If joining in the index, the `join()` method is easier\n",
    "  - The `join()` method joins on the left dataframe index and a right column of your choice\n",
    "- The `intersection()` method can be used to review the number of rows that result from an inner join without performing the join, in the event of joining large dataframes that consume a lot of memory\n",
    "  - The `difference()` method can be used to report the number of values in the first index that aren't in the second index\n",
    "    - This also tells you how many records are in a left or right join\n",
    "  - `symmetric_difference()` method reports what's lost on both sides\n",
    "- The `union()` method can be used to report the number of values kept in a full outer join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066b22a",
   "metadata": {},
   "source": [
    "### Enriching data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33126754",
   "metadata": {},
   "source": [
    "#### Arithmetic and statistics\n",
    "- Pandas methods for calculating stats and performing math operations applied to a dataframe performs the operations on columns by default, but can be used on rows\n",
    "  - `sub()`, `div()`, `std()`, and `mul()` are examples of math operator methods in pandas, for subtraction, division, standard deviation, and multiplication respectively\n",
    "- Two other useful methods are `rank()` and `pct_change()`\n",
    "  - `rank()` ranks the values of a volumn\n",
    "    - `rank()` can be used to calculate a numerical rank or a percentile, with 1.000 as the first value\n",
    "  - `pct_change()` calculates the percent change between periods\n",
    "- The `any()` and `all()` methods can be used on boolean masks to get binary values for each column that have any or all values that pass or fail the mask condition, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8e6e0",
   "metadata": {},
   "source": [
    "#### Binning\n",
    "- Binning helps break down continuous data into discrete groups\n",
    "  - This is sometimes easier to study, but some information is lost due to the reduced granularity\n",
    "- The `cut()` method can be used to bin based on value\n",
    "  - The default label option is the interval of values. Optionally, labels can be applied to the different bins.\n",
    "  - `cut()` will attempt to set the bin widths as equal as possible\n",
    "- The `qcut()` method breaks the data down into quartiles, setting each bin to equal number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e196e",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "- The `apply()` method can be used to apply functions to columns in a dataframe\n",
    "  - This method runs vectorized operations on entire columns or rows\n",
    "  - `applymap()` can be used to vectorize non-vectorized functions, alternatively `np.vectorize()` can be use\n",
    "  - Pandas has some functions that iterate over dataframes, but computation time increases as row count increases and is not recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78f635",
   "metadata": {},
   "source": [
    "#### Window calculations\n",
    "- These are calculations applied over a window or range of rows/columns\n",
    "- Rolling windows, or sliding windows, can be specified if the index is the Datetime data type or if the datetime columns is specified\n",
    "  - The `rolling()` method provides a `window` or `rolling` subclass which aggregate functions can be applied to\n",
    "  - The `agg()` method seen before can be used to specify functions for individual columns\n",
    "- Expanding windows, or growing windows, calculate cumulative values of the aggregate function\n",
    "  - The `expanding()` method is used to generate an `expanding` subclass\n",
    "  - Like `rolling()`, column specific aggregation can be applied with the `agg()` method\n",
    "- Finally, exponentially weighted moving windows can be generated with the `ewm()` method\n",
    "  - This window can be used to smooth data, placing higher importance on more recent observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0647d67",
   "metadata": {},
   "source": [
    "#### Pipes\n",
    "- Pipes facilitate chaining together operations that expect Pandas data structures as their first argument\n",
    "- This are useful to build complex workflows with easier to read code\n",
    "- Pipes are created using the `pipe()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05459df",
   "metadata": {},
   "source": [
    "### Aggregating data\n",
    "- Aggregation can be used to to summarize dataframes, often through row reduction\n",
    "- Numpy has many functions that work well with aggregation\n",
    "- The `agg()` method called directly on a dataframe returns a series back with the results\n",
    "- Multiple functions can be called on column, returning a dataframe object\n",
    "  - Nulls are returned for any combination of aggregation and column not explicitly asked for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f82b4",
   "metadata": {},
   "source": [
    "#### Grouping\n",
    "- Grouping can be used with aggregation to summarize per group\n",
    "- The `groupby()` method is used to perform the grouping\n",
    "  - Functions can be applied directly to the `groupby()` method or through the `agg()` method\n",
    "  - Further refinement of how each column is aggregated can be done by passing a dictionary with the columns and aggregating functions into `agg()`\n",
    "    - Passing multiple functions for a clolumn results in a multi index object\n",
    "      - List comprehensions can be used to remove the hierarchy\n",
    "    - Level can be passed to `groupby()` to group on a specific level of a hierarchical index\n",
    "- Grouping can be performed on multiple categories at once\n",
    "  - A `Grouper` object can be passed if, for instance, grouping is performed on the date index by quarter, as described in the book\n",
    "- The `transform()` method is introduced in this section and it applies a function to the data, returning an object with dimensions equal to what went in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e33d5c",
   "metadata": {},
   "source": [
    "#### Pivoting and crosstabs\n",
    "- A pivot table can be created using the `pivot_table()` method, specifying what to group on, the subset of columns to aggregate (optional), and the aggregating function(s) (optional)\n",
    "  - Passing columns as the `column` argument or `index` argument dictate the rotation of the output\n",
    "  - Multiple values can be passed to the `index` argument\n",
    "- The `crosstab()` function can be used to create a frequency table\n",
    "  - Syntax is similar to the pivot table, where `index` and `column` parameters must be specified\n",
    "  - Normalizing the output to percentage can be performed by passing the `normalize` parameter\n",
    "  - The aggregating function can be specified using the `aggfunc` parameter, the default function is count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599644a",
   "metadata": {},
   "source": [
    "### Time Series\n",
    "- Working with a time series opens up additional operations on top of those previously discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb53214",
   "metadata": {},
   "source": [
    "#### Time-based selection and filter\n",
    "- Data can be isolated by specific time periods using the `loc()` method, for example isolating by year\n",
    "  - The `loc()` method is optional when slicing by ranges, simple indexing can be used instead\n",
    "    - Ranges are inclusive of end dates\n",
    "  - Other time periods, like months and quarters, can be used\n",
    "- The first period of dates using the `first()` method, the last period of dates can be selected with `last()`\n",
    "  - Similar to `first()` and `last()`, `first_valid_index()` and `last_valid_index()` can be used to find the indices of the first and last non-null entries\n",
    "    - The `asof()` method gives the closest non-null entry before the date specified\n",
    "- Time based selection can be performed using the `at_time()` and `between_time()` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca91e40",
   "metadata": {},
   "source": [
    "#### Shifting for lagged data\n",
    "- Data can be shifted using the `shift()` method\n",
    "  - The default is a shift by one period, but this can be changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c53f3",
   "metadata": {},
   "source": [
    "#### Differenced data\n",
    "- Calculating how values change from one period to the next can be performed usin ghte `diff()` method\n",
    "  - The `diff()` method calculates the difference between the current time period and one time period back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d2f95",
   "metadata": {},
   "source": [
    "#### Resampling\n",
    "- Sometimes data isn't in the correct granularity and must be resampled\n",
    "- The `resample()` method can be used to perform this resampling\n",
    "  - This is used before an optional `agg()` call\n",
    "  - The method itself returns a `Resampler` object\n",
    "- Downsampling reductes the granularity of the data, upsampling does the opposite\n",
    "  - Both can be performed with the `resample()` method\n",
    "  - Pass the `asfreq()` method after the resampling eliminates the aggregation\n",
    "  - Upsampling can lead to `NaN` values if data isn't available to fill the new time periods\n",
    "    - There are a variety of ways to fill the `NaN` values, from padding to filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8209be",
   "metadata": {},
   "source": [
    "#### Merging Time Series\n",
    "- Merging is difficult if entries of the two groups to be merged don't have the same datetime\n",
    "- The `pd.merge_asof()` function will merge observations that are close in time\n",
    "  - This is similar to a left join\n",
    "  - The tolerance of the proximity in time can be specified\n",
    "  - This gives null values whenever a matching time in the time range can't be found\n",
    "- The `pd.merge_ordered()` function will match up equal keys and interleave keys without matches\n",
    "  - This is similar to an outer join\n",
    "  - This gives null values whenever times don't match up exactly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".book_env",
   "language": "python",
   "name": ".book_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
